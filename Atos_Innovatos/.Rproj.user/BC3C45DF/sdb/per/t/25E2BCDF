{
    "collab_server" : "",
    "contents" : "# Load required libraries (please install them with install.packages()  if missing )\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(shinyjs)\nlibrary(data.table)\nlibrary(DT)\nlibrary(rpart)\nlibrary(rattle)\nlibrary(randomForest)\nlibrary(sampling)\nlibrary(e1071)\nlibrary(caTools)\n\n# Include helper files\nsource('functions.R')\n\n# Add URL prefix for loading additional resource, such as images\naddResourcePath('resources',\"www\")\n\n# Custom ShinyJS hack code to let the boxes collapse automatically\njscode <- \"shinyjs.collapse = function(boxid) { $('#' + boxid).closest('.box').find('[data-widget=collapse]').click(); }\";\n\n# Define variables for having the datasat globally\nassign(\"data\", NULL, envir = .GlobalEnv);\n\n#assign(\"data.labels\", NULL, envir = .GlobalEnv);\n#assign(\"input$variable1\",NULL,envir = .GlobalEnv);\n\n\n\nserver <- function(input, output,session) {\n  \n\n # loadData()\n\n  # Function that dynamically updates our dropdownlists\n # data <- loadData1(input$file1$datapath,header = input$header,sep = input$sep, quote = input$quote)\n  \n  \n\n \n  observe({\n\n    \n    # For performance reasons, only execute if the tab is actually opened by the user.\n    # Logic behind the data table overview tab\n    if(input$tab == \"Upload\")\n    {\n      observeEvent(input$btnUpload, {\n      data <<- loadData1(input$file1$datapath,header = input$header,sep = input$sep, quote = input$quote);\n      })\n    }\n    \n    \n    if (input$tab == 'Data')\n    {\n        # input$file1 will be NULL initially. After the user selects\n        # and uploads a file, head of that data file by default,\n        # or all rows if selected, will be shown.\n       output$contents <- renderTable({\n          data\n      })\n        \n    }\n    \n    \n    # Logic behind the summary statistcs tab\n    if (input$tab == 'ExploreSummary')\n    {\n      output$dtSummary = renderDataTable({\n        datatable(createSummaryTable(), options = list(scrollX = TRUE,pageLength = 20))\n        \n      })\n      \n    }\n    \n    # Logic behind the density compare tab\n    if (input$tab == 'ExploreDensity')\n    {\n      output$densitySelectInput <- renderUI({\n        dataNames <- all_column()\n        selectInput(\"factor_column\", \"Choose Option:\",dataNames ) \n      })\n      output$densitySelectInput2 <- renderUI({\n        dataNames <- all_column()\n        selectInput(\"column\", \"Choose Option:\",dataNames ) \n      })\n      output$DensityPlot <- renderPlot({ plotDensity(yVar,input$column) });\n    }\n    \n    if (input$tab == 'ExploreCorrelation')\n    {\n      output$CorrelogramPlot <- renderPlot({ \n        print(input$intNoCorrVars)\n        plotCorrGram(input$intNoCorrVars)\n        \n      });\n    }\n    \n    # Logic behind the case stats overview tab\n    if (input$tab == 'CaseOverview')\n    {\n      output$overviewSelector <- renderUI({\n      dataNames <- all_column()\n      selectInput(\"overview\", \"Choose Option:\",dataNames ) \n      })\n      observeEvent(input$btnOverview, {\n        output$CaseStatsPlot <- renderPlot({ plotCaseStats(input$overview) });  \n      })\n       # req(input$file1)\n       # data <- loadData1(input$file1$datapath,header = input$header,sep = input$sep, quote = input$quote)\n       # s_options <<- all_column();\n       # updateSelectInput(session, \"c_name\",\n        #                  choices = s_options\n       # ) \n      \n      \n      #print(input$variable1)\n   \n    }\n    \n    \n    \n    \n    #############################################SMOTE\n    # Below code is triggered once a button has been pressed.\n   #if(input$tab == \"Rebalance\") {\n    # output$rebalanceSelectInput <- renderUI({\n    #   dataNames <- all_column()\n    #   selectInput(\"smote_column\", \"Choose Option:\",dataNames ) \n   #  })\n    \n    \n    \n    \n    if(input$tab == \"Rebalance\") {\n      output$rebalanceSelectInput <- renderUI({\n        dataNames <- all_column()\n        selectInput(\"smote_column\", \"Choose Option:\",dataNames ) \n      })\n      smote_col <- input$smote_column\n   \n    \n    }\n  })\n  \n\n  observeEvent(input$btnRunSMOTE, {\n    \n    # This code implemented the SMOTE example\n    \n    \n    #data_old <-data.table(copy(data)) \n    # data_old <- subset(data_old,select=-TIMESTAMP);\n    # print(\"SMOTE\")\n    \n    print(smote_col)\n    table(data$smote_col) #Statistics before \n    print(table(data$smote_col))\n    data_balanced <- SMOTE(form = smote_col ~., data = data, perc.over = 500,perc.under = 120)\n    \n    output$Plot_SMOTE_Old_CaseStats <- renderPlot({ \n      \n      out <- table(data$smote_col)\n      linch <-  max(strwidth(out, \"inch\")+0.7, na.rm = TRUE)\n      par(mai=c(1.02,linch,0.82,0.42))\n      x <- barplot(out,horiz = TRUE,cex.names=0.9,las=1,xlab=paste(\"# of cases\"),xlim=c(0,max(out,na.rm=TRUE)+50),col=\"cornflowerblue\",main = 'Before SMOTE')\n      text(out+pmin((5+out*0.7),20),x,labels=round(out), col=\"black\",cex=0.75)\n      \n    })\n    \n    output$Plot_SMOTE_New_CaseStats <- renderPlot({ \n      \n      out <- table(data_balanced$smote_col)\n      linch <-  max(strwidth(out, \"inch\")+0.7, na.rm = TRUE)\n      par(mai=c(1.02,linch,0.82,0.42))\n      x <- barplot(out,horiz = TRUE,cex.names=0.9,las=1,xlab=paste(\"# of cases\"),xlim=c(0,max(out,na.rm=TRUE)+50),col=\"cornflowerblue\",main = 'After SMOTE')\n      text(out+pmin((5+out*0.7),20),x,labels=round(out), col=\"black\",cex=0.75)\n      \n    })\n    \n    output$dtSMOTEresult = renderDataTable({\n      datatable(data_balanced, options = list(scrollX = TRUE,pageLength = 20))\n    })\n    \n    # Call our custom box collapse hack\n    js$collapse(\"Box_SMOTE_CaseStats1\")\n    js$collapse(\"Box_SMOTE_Dataset\")\n    \n  })\n  \n\n  \n  \n  \n  \n  \n  \n  observeEvent(input$btnRunRPart, {\n    # Code below implements the decision tree functionality\n    \n    isolate({\n      \n      if (input$chkRPartWithSMOTE == TRUE )\n      {\n        data_old <-data.table(copy(data)) \n        data_old <- subset(data_old,select=-TIMESTAMP);\n        data_balanced <-SMOTE(form = FAIL ~., data = data_old, perc.over = 500,perc.under = 120)\n      } else {\n        data_balanced <-data.table(copy(data))\n        data_balanced <- subset(data_balanced,select=-TIMESTAMP);\n      }\n      \n      \n      # grow tree \n      fit <- rpart(FAIL ~ .,\n                   method=\"class\", data=data_balanced, control=rpart.control(minsplit=2))\n      \n      output$Out_rpart = renderPrint({\n        summary(fit)\n      })\n      \n      \n      output$Plot_rpart = renderPlot({\n        fancyRpartPlot(fit,main=\"Decision Tree\",digits=10)\n      })\n      \n    })\n    js$collapse(\"Box_RPart_Results_plot\");\n    js$collapse(\"Box_RPart_Results_summary\");\n    \n  })\n  \n  \n  observeEvent(input$btnRunRF, {\n    # Below code implements the RandomForest modelling functionality\n    \n    isolate({\n      \n      \n      if (input$chkRFWithTest == TRUE)\n      {\n        # Do a 75/25 split\n        sample = sample.split(data$FAIL, SplitRatio = .75)\n        data_train = subset(copy(data), sample == TRUE)\n        data_test = subset(copy(data), sample == FALSE)\n      } else {\n        # Just make both sets the same\n        data_train <- copy(data);\n        data_test <- copy(data);\n      }\n      \n      \n      if (input$chkRFWithSMOTE == TRUE )\n      {\n        data_old <- data_train\n        data_old <- subset(data_old,select=-TIMESTAMP);\n        data_balanced <-SMOTE(form = FAIL ~., data = data_old, perc.over = 500,perc.under = 120)\n      } else {\n        data_balanced <- data_train #speeding up by turning into data.table\n        data_balanced <- subset(data_balanced,select=-TIMESTAMP);\n      }\n      \n      columns.to.keep<-names(which(colMeans(is.na(data_balanced)) < 0.5)) # this removes those columns with more than 50% NULLs\n      data_balanced<-subset(data_balanced,select = columns.to.keep) #the columns will stay which has less than 50% NAs\n      \n      nzv <- nearZeroVar(data_balanced)\n      data_balanced <- data_balanced[,-nzv]\n      \n      if (input$chkRFWithImpute == TRUE )\n      {\n        # Since RandomForest cannot handle missing values, we will try to impute them\n        data.imputed <- rfImpute(FAIL ~ ., data=data_balanced, iter=2, ntree=30)\n      } else {\n        \n        # The very cheap version of setting the missing values to something very high\n        data.imputed <- data_balanced;\n        data.imputed[is.na(data.imputed)]<--9999 #just some random number that never happened in the data\n      }\n      \n      #### Random Forest\n      fit <- randomForest(FAIL ~ .,\n                          data=data.imputed, \n                          importance=TRUE, \n                          ntree=input$intNoOfRF)\n      \n      \n      output$plot_rf_varimp1 = renderPlot({\n        varImpPlot(fit,type=1,main = \"Variable Importance\")\n      })\n      \n      output$plot_rf_varimp2 = renderPlot({\n        varImpPlot(fit,type=2,main = \"Variable Importance\")\n      })        \n      \n      output$plot_rf_error = renderPlot({\n        plot(fit,main = \"Error\")\n      })\n      \n      \n      test_data <- data_test\n      test_result <- test_data$FAIL; # Make sure we have the results seaprate\n      \n      test_data <- subset(test_data,select=c(-TIMESTAMP,-FAIL))\n      \n      pred_data <- predict(object = fit, newdata = test_data)\n      \n      xtab <- table(pred_data, test_result)\n      \n      output$Out_rf = renderPrint({\n        confusionMatrix(xtab)\n      })\n      \n      \n    })\n    \n    js$collapse(\"Box_RF_Results_plot\");\n    js$collapse(\"Box_RF_Results_conf\");\n    \n    \n  })\n  \n  \n  observeEvent(input$btnRunFeature, {\n    # Code below calls the function to find the TOP100 most promising features\n    \n    output$FeatureTable = renderDataTable({\n      isolate({\n        datatable(findTop100Features(copy(data),'FAIL',SMOTE_BALANCE = input$chkFeatureWithSMOTE, USE_RF = input$chkFeatureWithRF, USE_XGBOOST = input$chkFeatureWithXG,RETURN_VAR_VECTOR = FALSE), options = list(scrollX = TRUE,pageLength = 20))\n      })\n      \n    })\n    \n    \n  })\n  \n  \n  observeEvent(input$btnRunSVM, {\n    # This code implements the SVM modelling functionality\n    \n    isolate({\n      \n      if (input$chkSVMWithTest == TRUE)\n      {\n        # Do a 75/25 split\n        sample = sample.split(data$FAIL, SplitRatio = .75)\n        data_train = subset(copy(data), sample == TRUE)\n        data_test = subset(copy(data), sample == FALSE)\n      } else {\n        # Just make both sets the same\n        data_train <- copy(data);\n        data_test <- copy(data);\n      }\n      \n      if (input$chkSVMWithTOPFeatures == TRUE)\n      {\n        top100_cols <- findTop100Features(data_train,'FAIL');\n      }\n      \n      if (input$chkSVMWithSMOTE == TRUE )\n      {\n        data_old <- data_train\n        data_old <- subset(data_old,select=-TIMESTAMP);\n        data_balanced <-SMOTE(form = FAIL ~., data = data_old, perc.over = 500,perc.under = 120)\n      } else {\n        data_balanced <- data_train \n        data_balanced <- subset(data_balanced,select=-TIMESTAMP);\n      }\n      \n      if (input$chkSVMWithTOPFeatures == TRUE)\n      {\n        data_balanced <- subset(data_balanced,select=c(top100_cols,'FAIL'));\n      }\n      \n      columns.to.keep<-names(which(colMeans(is.na(data_balanced)) < 0.5)) # this removes those columns with more than 50% NULLs\n      data_balanced<-subset(data_balanced,select = columns.to.keep) #the columns will stay which has less than 50% NAs\n      \n      nzv <- nearZeroVar(data_balanced)\n      data_balanced <- data_balanced[,-nzv]\n      \n      \n      data_balanced[is.na(data_balanced)]<--9999\n      \n      xData <- subset(data_balanced,select=-FAIL);\n      yData <- data_balanced$FAIL;\n      \n      \n      fit.svm<-svm(x= xData,y= yData)\n      \n      # Get our test set from the original split\n      test_data <- data_test\n      test_result <- test_data$FAIL; # Make sure we have the results seaprate - as some functions like it separate\n      \n      # Remove the target and timestamp\n      test_data <- subset(test_data,select=c(-TIMESTAMP,-FAIL))\n      \n      # NA's are not desired, as it hinders prediction.\n      test_data[is.na(test_data)]<--9999 #just some random number that never happened in the data\n      \n      if (input$chkSVMWithTOPFeatures == TRUE)\n      {\n        test_data<-subset(test_data,select = c(top100_cols));\n      }\n      \n      test_data<-subset(test_data,select = setdiff(columns.to.keep,'FAIL')) #the columns will stay which has less than 50% NAs\n      test_data <- test_data[,-nzv]\n      \n      # Do the actual prediction with our previously trained model\n      pred_data <- predict(object = fit.svm, newdata = test_data)\n      \n      xtab <- table(pred_data, test_result)\n      \n      # Write results back to the app\n      output$Out_svm = renderPrint({\n        isolate({\n          cat(\"Started with options:\\r\\n\")\n          cat(\"* SMOTE : \", input$chkSVMWithSMOTE,\"\\r\\n\")\n          cat(\"* TOP100 Features : \",input$chkSVMWithTOPFeatures,\"\\r\\n\")\n          cat(\"* TEST/TRAINING SET : \",input$chkSVMWithTest,\"\\r\\n\")\n          cat(\"---------------------------------------------------------\\r\\n\")\n          confusionMatrix(xtab)\n        })\n      })\n      \n      \n    })\n    \n    \n    \n  })\n  \n}",
    "created" : 1505318805106.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1990735618",
    "id" : "25E2BCDF",
    "lastKnownWriteTime" : 1505328078,
    "last_content_update" : 1505328078151,
    "path" : "F:/Shekhar/AtosInnovatos2017-master/server.R",
    "project_path" : "server.R",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}